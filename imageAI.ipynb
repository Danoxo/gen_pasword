{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpsv00+CuH+ON7CFKvSx6l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danoxo/gen_pasword/blob/main/imageAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv5Hu7l4PEMy",
        "outputId": "bd87b9f3-87f2-4fe1-e6c9-9fc9c7913f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imageAI\n",
            "  Downloading imageai-3.0.3-py3-none-any.whl.metadata (340 bytes)\n",
            "Downloading imageai-3.0.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imageAI\n",
            "Successfully installed imageAI-3.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install imageAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/3.0.0-pretrained/yolov3.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKYClcoyPWcR",
        "outputId": "dd8ea46c-4133-48b6-955b-b9dbddcb6e50"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-28 23:06:45--  https://github.com/OlafenwaMoses/ImageAI/releases/download/3.0.0-pretrained/yolov3.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/125932201/adc7efe4-b3ac-4710-8a05-0bfefa255bae?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240828%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240828T230646Z&X-Amz-Expires=300&X-Amz-Signature=a68cc4b9e99c995cc1b8b715c52ff9dc0a819468486dd11d93634646f64374fb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dyolov3.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-08-28 23:06:46--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/125932201/adc7efe4-b3ac-4710-8a05-0bfefa255bae?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240828%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240828T230646Z&X-Amz-Expires=300&X-Amz-Signature=a68cc4b9e99c995cc1b8b715c52ff9dc0a819468486dd11d93634646f64374fb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dyolov3.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248148565 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.pt’\n",
            "\n",
            "yolov3.pt           100%[===================>] 236.65M   119MB/s    in 2.0s    \n",
            "\n",
            "2024-08-28 23:06:48 (119 MB/s) - ‘yolov3.pt’ saved [248148565/248148565]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imageai.Detection import ObjectDetection\n",
        "detector = ObjectDetection()\n",
        "model_path = \"/content/yolov3.pt\"\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath(model_path)\n",
        "detector.loadModel()"
      ],
      "metadata": {
        "id": "IbsrmW1zQIs4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector.CustomObjects()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1hwZgJWFQzcz",
        "outputId": "29ba3f26-6b0c-4807-b612-371c72251111"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'person': False,\n",
              " 'bicycle': False,\n",
              " 'car': False,\n",
              " 'motorbike': False,\n",
              " 'aeroplane': False,\n",
              " 'bus': False,\n",
              " 'train': False,\n",
              " 'truck': False,\n",
              " 'boat': False,\n",
              " 'traffic_light': False,\n",
              " 'fire_hydrant': False,\n",
              " 'stop_sign': False,\n",
              " 'parking_meter': False,\n",
              " 'bench': False,\n",
              " 'bird': False,\n",
              " 'cat': False,\n",
              " 'dog': False,\n",
              " 'horse': False,\n",
              " 'sheep': False,\n",
              " 'cow': False,\n",
              " 'elephant': False,\n",
              " 'bear': False,\n",
              " 'zebra': False,\n",
              " 'giraffe': False,\n",
              " 'backpack': False,\n",
              " 'umbrella': False,\n",
              " 'handbag': False,\n",
              " 'tie': False,\n",
              " 'suitcase': False,\n",
              " 'frisbee': False,\n",
              " 'skis': False,\n",
              " 'snowboard': False,\n",
              " 'sports_ball': False,\n",
              " 'kite': False,\n",
              " 'baseball_bat': False,\n",
              " 'baseball_glove': False,\n",
              " 'skateboard': False,\n",
              " 'surfboard': False,\n",
              " 'tennis_racket': False,\n",
              " 'bottle': False,\n",
              " 'wine_glass': False,\n",
              " 'cup': False,\n",
              " 'fork': False,\n",
              " 'knife': False,\n",
              " 'spoon': False,\n",
              " 'bowl': False,\n",
              " 'banana': False,\n",
              " 'apple': False,\n",
              " 'sandwich': False,\n",
              " 'orange': False,\n",
              " 'broccoli': False,\n",
              " 'carrot': False,\n",
              " 'hot_dog': False,\n",
              " 'pizza': False,\n",
              " 'donut': False,\n",
              " 'cake': False,\n",
              " 'chair': False,\n",
              " 'sofa': False,\n",
              " 'pottedplant': False,\n",
              " 'bed': False,\n",
              " 'diningtable': False,\n",
              " 'toilet': False,\n",
              " 'tvmonitor': False,\n",
              " 'laptop': False,\n",
              " 'mouse': False,\n",
              " 'remote': False,\n",
              " 'keyboard': False,\n",
              " 'cell_phone': False,\n",
              " 'microwave': False,\n",
              " 'oven': False,\n",
              " 'toaster': False,\n",
              " 'sink': False,\n",
              " 'refrigerator': False,\n",
              " 'book': False,\n",
              " 'clock': False,\n",
              " 'vase': False,\n",
              " 'scissors': False,\n",
              " 'teddy_bear': False,\n",
              " 'hair_drier': False,\n",
              " 'toothbrush': False}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detections = detector.detectObjectsFromImage(\n",
        "    input_image=\"/content/Image20240828171606.jpg\",\n",
        "    output_image_path=\"output_image.jpg\",\n",
        "    minimum_percentage_probability=30)"
      ],
      "metadata": {
        "id": "1M7y_WEGRVJI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(detections)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcrydu4oSFp2",
        "outputId": "68ccc9fc-8aed-4954-9fa5-928cf5a5c4f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'person', 'percentage_probability': 99.96, 'box_points': [48, 44, 76, 127]}, {'name': 'person', 'percentage_probability': 99.97, 'box_points': [15, 38, 38, 96]}, {'name': 'person', 'percentage_probability': 99.97, 'box_points': [85, 39, 114, 117]}, {'name': 'person', 'percentage_probability': 99.94, 'box_points': [109, 51, 136, 105]}, {'name': 'person', 'percentage_probability': 99.95, 'box_points': [34, 41, 50, 92]}, {'name': 'person', 'percentage_probability': 99.86, 'box_points': [79, 43, 94, 111]}, {'name': 'bicycle', 'percentage_probability': 99.89, 'box_points': [22, 66, 39, 110]}, {'name': 'bicycle', 'percentage_probability': 99.81, 'box_points': [56, 80, 72, 137]}, {'name': 'bicycle', 'percentage_probability': 99.64, 'box_points': [92, 78, 109, 125]}, {'name': 'bicycle', 'percentage_probability': 98.72, 'box_points': [111, 74, 131, 132]}, {'name': 'car', 'percentage_probability': 97.04, 'box_points': [129, 50, 264, 165]}, {'name': 'car', 'percentage_probability': 91.82, 'box_points': [116, 9, 160, 35]}, {'name': 'truck', 'percentage_probability': 87.79, 'box_points': [29, 1, 73, 32]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in detections:\n",
        "  print(i[\"name\"], \":\", i[\"percentage_probability\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBoiukPwSN6P",
        "outputId": "0ee7d94a-d134-49b1-b0ee-b678b1925365"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "person : 99.96\n",
            "person : 99.97\n",
            "person : 99.97\n",
            "person : 99.94\n",
            "person : 99.95\n",
            "person : 99.86\n",
            "bicycle : 99.89\n",
            "bicycle : 99.81\n",
            "bicycle : 99.64\n",
            "bicycle : 98.72\n",
            "car : 97.04\n",
            "car : 91.82\n",
            "truck : 87.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "05qJ8q8oSktb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#funcion"
      ],
      "metadata": {
        "id": "QoPxJUvIS_ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects_on_road(input_image,output_image,model_path):\n",
        "  detector = ObjectDetection()\n",
        "  model_path = model_path\n",
        "  detector.setModelTypeAsYOLOv3()\n",
        "  detector.setModelPath(model_path)\n",
        "  detector.loadModel()\n",
        "  detections = detector.detectObjectsFromImage(\n",
        "  input_image= input_image,\n",
        "  output_image_path= output_image,\n",
        "  minimum_percentage_probability=30)\n",
        "  return detections\n",
        "\n",
        "def analyze_objects(detections):\n",
        "  road_objects = []\n",
        "  if len(detections) > 0:\n",
        "    for detection in detections:\n",
        "      if detection[\"name\"] in [\"car\", \"motorbike\", \"bicycle\", \"person\", \"bus\", 'train']:\n",
        "        road_objects.append(detection)\n",
        "  return road_objects\n",
        "\n",
        "\n",
        "def road_safety_rules():\n",
        "    print()\n",
        "    print(\"¡Hola! Esta SafetyAI - una aplicación de seguridad vial.\")\n",
        "    print(\"Las normas de seguridad vial son muy importantes, y yo te ayudaré a recordarlas.\")\n",
        "    print(\"Recuerda: ¡es muy importante respetar las normas de seguridad vial y ser prudente al acercarse a la carretera!\")\n",
        "    print(\"Utiliza los semáforos y los pasos de peatones.\")\n",
        "    print(\"Nunca cruces una carretera por lugares que no estén diseñados para ello.\")\n",
        "    print(\"Recuerde que, al cruzar una carretera, debe ser igualmente prudente y previsible.\")\n",
        "    print(\"Tenga cuidado en la carretera y ¡buena suerte!\")"
      ],
      "metadata": {
        "id": "2lrTlxN0TCfA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = \"/content/Image20240828173540.jpg\"\n",
        "output_image = \"pepe.jpg\"\n",
        "detections = detect_objects_on_road(input_image, output_image, \"/content/yolov3.pt\")\n",
        "road_objects = analyze_objects(detections)\n",
        "if len(road_objects) > 0:\n",
        "  print(\"Detected road users:\")\n",
        "  for obj in road_objects:\n",
        "    print(obj[\"name\"], \":\", obj[\"percentage_probability\"], \":\", obj[\"box_points\"])\n",
        "else:\n",
        "  print(\"No road users detected\")\n",
        "road_safety_rules()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92HlKh7NWCgZ",
        "outputId": "a9ed8385-174f-4c47-99a5-fc3a5f7f4719"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imageai/Detection/__init__.py:255: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(self.__model_path, map_location=self.__device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected road users:\n",
            "person : 99.99 : [924, 292, 993, 477]\n",
            "person : 100.0 : [98, 299, 255, 606]\n",
            "person : 100.0 : [580, 294, 660, 469]\n",
            "person : 99.95 : [387, 329, 452, 487]\n",
            "person : 99.98 : [499, 340, 531, 419]\n",
            "person : 99.84 : [724, 335, 759, 413]\n",
            "person : 99.94 : [689, 319, 720, 407]\n",
            "person : 99.89 : [478, 337, 507, 417]\n",
            "person : 98.41 : [1017, 308, 1041, 358]\n",
            "person : 91.61 : [1061, 310, 1084, 356]\n",
            "person : 99.79 : [555, 338, 588, 420]\n",
            "person : 96.27 : [765, 336, 787, 384]\n",
            "person : 48.31 : [1174, 293, 1199, 375]\n",
            "person : 79.87 : [1109, 307, 1133, 353]\n",
            "bicycle : 99.64 : [43, 432, 289, 673]\n",
            "bicycle : 99.74 : [581, 379, 662, 512]\n",
            "bicycle : 99.86 : [399, 405, 439, 501]\n",
            "bicycle : 99.21 : [552, 387, 582, 427]\n",
            "\n",
            "¡Hola! Esta SafetyAI - una aplicación de seguridad vial.\n",
            "Las normas de seguridad vial son muy importantes, y yo te ayudaré a recordarlas.\n",
            "Recuerda: ¡es muy importante respetar las normas de seguridad vial y ser prudente al acercarse a la carretera!\n",
            "Utiliza los semáforos y los pasos de peatones.\n",
            "Nunca cruces una carretera por lugares que no estén diseñados para ello.\n",
            "Recuerde que, al cruzar una carretera, debe ser igualmente prudente y previsible.\n",
            "Tenga cuidado en la carretera y ¡buena suerte!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2"
      ],
      "metadata": {
        "id": "Yy53RBLraPWX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imag = cv2.imread(\"/content/pepe.jpg\")\n",
        "recorte = imag[387: 427, 552: 582]\n",
        "cv2_imshow(recorte)\n",
        "cv2.imwrite(\"cicla1.jpg\", recorte)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "LRcc7I0UaSO_",
        "outputId": "fe98e33f-950d-4584-f409-fd45b4eda223"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=30x40>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}